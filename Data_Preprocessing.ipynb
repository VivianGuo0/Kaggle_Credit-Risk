{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b608f83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ROOT = '/kaggle/input/home-credit-credit-risk-model-stability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd997fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edd88c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipline --- 数据预处理\n",
    "## 对不同类型的数据做了基本的转化、将一些日期转换成间隔时间、删除缺失值过多的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c512925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "\n",
    "    def set_table_dtypes(df):\n",
    "        for col in df.columns:\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "            elif col in [\"date_decision\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "            elif col[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String))\n",
    "            elif col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "        return df\n",
    "\n",
    "    def handle_dates(df):\n",
    "        for col in df.columns:\n",
    "            if col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))  #!!?\n",
    "                df = df.with_columns(pl.col(col).dt.total_days()) # t - t-1\n",
    "        df = df.drop(\"date_decision\", \"MONTH\")\n",
    "        return df\n",
    "\n",
    "    def filter_cols(df):\n",
    "        for col in df.columns:\n",
    "            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n",
    "                isnull = df[col].is_null().mean()\n",
    "                if isnull > 0.7:\n",
    "                    df = df.drop(col)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n",
    "                freq = df[col].n_unique()\n",
    "                if (freq == 1) | (freq > 200):\n",
    "                    df = df.drop(col)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e0c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregator 类旨在生成用于聚合数据的表达式列表。\n",
    "\n",
    "## 数值型：最大值、最小值、mean\n",
    "## 日期型：最大值、最小值、mean\n",
    "## str型：最大值、最后值\n",
    "## 其他（T、L）：最大值、最后值\n",
    "## 计数型：选择包含 \"num_group\" 的列，最大值、最后值\n",
    "\n",
    "## 最后把这些表合成一个表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "942e05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregator:\n",
    "    #Please add or subtract features yourself, be aware that too many features will take up too much space.\n",
    "    def num_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        \n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return expr_max +expr_last+expr_mean\n",
    "    \n",
    "    def date_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"D\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        #expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return  expr_max +expr_last+expr_mean\n",
    "    \n",
    "    def str_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        #expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        #expr_count = [pl.count(col).alias(f\"count_{col}\") for col in cols]\n",
    "        return  expr_max +expr_last#+expr_count\n",
    "    \n",
    "    def other_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        #expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        return  expr_max +expr_last\n",
    "    \n",
    "    def count_expr(df):\n",
    "        cols = [col for col in df.columns if \"num_group\" in col]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols] \n",
    "        #expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        return  expr_max +expr_last\n",
    "    \n",
    "    def get_exprs(df):\n",
    "        exprs = Aggregator.num_expr(df) + \\\n",
    "                Aggregator.date_expr(df) + \\\n",
    "                Aggregator.str_expr(df) + \\\n",
    "                Aggregator.other_expr(df) + \\\n",
    "                Aggregator.count_expr(df)\n",
    "\n",
    "        return exprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7b6fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取数据并进行预处理\n",
    "## 读取file，对深度 > 0的，Aggregator.get_exprs(df)\n",
    "## 多files聚合后df.unique(subset=[\"case_id\"]) 去除重复ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a686bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path, depth=None):\n",
    "    df = pl.read_parquet(path)\n",
    "    df = df.pipe(Pipeline.set_table_dtypes)\n",
    "    if depth in [1,2]:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df)) \n",
    "    return df\n",
    "\n",
    "def read_files(regex_path, depth=None):\n",
    "    chunks = []\n",
    "    \n",
    "    for path in glob(str(regex_path)):\n",
    "        df = pl.read_parquet(path)\n",
    "        df = df.pipe(Pipeline.set_table_dtypes)\n",
    "        if depth in [1, 2]:\n",
    "            df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "        chunks.append(df)\n",
    "    \n",
    "    df = pl.concat(chunks, how=\"vertical_relaxed\")\n",
    "    df = df.unique(subset=[\"case_id\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b76a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 特征工程\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed3b8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng(df_base, depth_0, depth_1, depth_2):\n",
    "    df_base = (\n",
    "        df_base\n",
    "        .with_columns(\n",
    "            month_decision = pl.col(\"date_decision\").dt.month(),\n",
    "            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n",
    "        )\n",
    "    )\n",
    "    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n",
    "    df_base = df_base.pipe(Pipeline.handle_dates)\n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad7e1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 将 DataFrame 转换为 Pandas DataFrame，并可选地将指定列转换为分类类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbf91721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pandas(df_data, cat_cols=None):\n",
    "    df_data = df_data.to_pandas()\n",
    "    if cat_cols is None:\n",
    "        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n",
    "    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n",
    "    return df_data, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27fd4c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 减少 DataFrame 的内存使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfecb43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if str(col_type)==\"category\":\n",
    "            continue\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            continue\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfd7946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT            = Path(\"./\")\n",
    "\n",
    "TRAIN_DIR       = ROOT / \"parquet_files\" / \"train\"\n",
    "TEST_DIR        = ROOT / \"parquet_files\" / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 通过调用 read_file 和 read_files 函数来读取不同文件的数据，并将其存储在 data_store 字典中的相应键下\n",
    "## 这些键是 \"df_base\"、\"depth_0\"、\"depth_1\" 和 \"depth_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62e36000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 15s, sys: 1min 16s, total: 3min 31s\n",
      "Wall time: 59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_store = {\n",
    "    \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n",
    "        read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n",
    "        read_file(TRAIN_DIR / \"train_applprev_2.parquet\", 2),\n",
    "        read_file(TRAIN_DIR / \"train_person_2.parquet\", 2)\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d8a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 对训练数据进行进一步的特征处理和列选择\n",
    "## 特征工程\n",
    "## 释放内存\n",
    "## Pipeline操作\n",
    "## 转成Numpy，标注categorical\n",
    "## 根据每个列的缺失值数量将列分组，并尝试通过相关性分析来减少每个组中的列数量。最后，选择的列保存在 uses 变量中\n",
    "\n",
    "## 最终获得了df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a51b31c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:\t (1526659, 861)\n",
      "Memory usage of dataframe is 4322.75 MB\n",
      "Memory usage after optimization is: 1528.81 MB\n",
      "Decreased by 64.6%\n",
      "train data shape:\t (1526659, 472)\n",
      "Use these ['case_id', 'WEEK_NUM', 'target', 'month_decision', 'weekday_decision', 'credamount_770A', 'applicationcnt_361L', 'applications30d_658L', 'applicationscnt_1086L', 'applicationscnt_464L', 'applicationscnt_867L', 'clientscnt_1022L', 'clientscnt_100L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_304L', 'clientscnt_360L', 'clientscnt_493L', 'clientscnt_533L', 'clientscnt_887L', 'clientscnt_946L', 'deferredmnthsnum_166L', 'disbursedcredamount_1113A', 'downpmt_116A', 'homephncnt_628L', 'isbidproduct_1095L', 'mobilephncnt_593L', 'numactivecreds_622L', 'numactivecredschannel_414L', 'numactiverelcontr_750L', 'numcontrs3months_479L', 'numnotactivated_1143L', 'numpmtchanneldd_318L', 'numrejects9m_859L', 'sellerplacecnt_915L', 'max_mainoccupationinc_384A', 'max_birth_259D', 'max_num_group1_9']\n",
      "####### NAN count = 0\n",
      "####### NAN count = 918788\n",
      "Use these ['dateofbirth_337D', 'days180_256L', 'days30_165L', 'days360_512L', 'firstquarter_103L', 'fourthquarter_440L', 'secondquarter_766L', 'thirdquarter_1082L', 'max_debtoutstand_525A', 'max_debtoverdue_47A', 'max_refreshdate_3813885D', 'mean_refreshdate_3813885D']\n",
      "####### NAN count = 140968\n",
      "Use these ['pmtscount_423L', 'pmtssum_45A']\n",
      "####### NAN count = 954021\n",
      "####### NAN count = 806659\n",
      "####### NAN count = 866332\n",
      "####### NAN count = 418178\n",
      "Use these ['amtinstpaidbefduel24m_4187115A', 'numinstlswithdpd5_4187116L']\n",
      "####### NAN count = 561124\n",
      "Use these ['annuitynextmonth_57A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'numinstls_657L', 'totalsettled_863A']\n",
      "####### NAN count = 4\n",
      "Use these ['mindbddpdlast24m_3658935P']\n",
      "####### NAN count = 613202\n",
      "####### NAN count = 948244\n",
      "Use these ['mindbdtollast24m_4525191P']\n",
      "####### NAN count = 972827\n",
      "####### NAN count = 467175\n",
      "Use these ['avginstallast24m_3658937A', 'maxinstallast24m_3658928A']\n",
      "####### NAN count = 624875\n",
      "####### NAN count = 757006\n",
      "####### NAN count = 841181\n",
      "####### NAN count = 1026987\n",
      "####### NAN count = 455190\n",
      "####### NAN count = 460822\n",
      "Use these ['commnoinclast6m_3546845L', 'maxdpdfrom6mto36m_3546853P']\n",
      "####### NAN count = 343375\n",
      "####### NAN count = 833735\n",
      "####### NAN count = 887659\n",
      "Use these ['daysoverduetolerancedd_3976961L', 'numinsttopaygr_769L']\n",
      "####### NAN count = 452594\n",
      "####### NAN count = 977119\n",
      "Use these ['eir_270L']\n",
      "####### NAN count = 190833\n",
      "####### NAN count = 859214\n",
      "####### NAN count = 482103\n",
      "####### NAN count = 453587\n",
      "Use these ['lastapplicationdate_877D', 'mean_creationdate_885D', 'max_num_group1', 'last_num_group1', 'max_num_group2_14', 'last_num_group2_14']\n",
      "####### NAN count = 305137\n",
      "Use these ['lastapprcredamount_781A', 'lastapprdate_640D']\n",
      "####### NAN count = 442041\n",
      "####### NAN count = 977975\n",
      "Use these ['lastrejectcredamount_222A', 'lastrejectdate_50D']\n",
      "####### NAN count = 769046\n",
      "####### NAN count = 511255\n",
      "Use these ['mastercontrelectronic_519L', 'mastercontrexist_109L', 'maxannuity_159A', 'maxdebt4_972A', 'maxdpdlast24m_143P', 'maxdpdlast3m_392P', 'maxdpdtolerance_374P']\n",
      "####### NAN count = 306019\n",
      "####### NAN count = 960953\n",
      "####### NAN count = 705504\n",
      "####### NAN count = 876276\n",
      "####### NAN count = 826000\n",
      "####### NAN count = 829402\n",
      "####### NAN count = 1032856\n",
      "####### NAN count = 766958\n",
      "Use these ['numinstpaidearly_338L', 'numinstpaidearly5d_1087L', 'numinstpaidlate1d_3546852L']\n",
      "####### NAN count = 452593\n",
      "####### NAN count = 455081\n",
      "Use these ['numinstlsallpaid_934L']\n",
      "####### NAN count = 445669\n",
      "Use these ['numinstlswithdpd10_728L', 'numinstlswithoutdpd_562L']\n",
      "####### NAN count = 456495\n",
      "Use these ['numinstpaid_4499208L']\n",
      "####### NAN count = 847191\n",
      "####### NAN count = 446983\n",
      "Use these ['numinstregularpaidest_4493210L', 'numinstpaidearly5dest_4493211L', 'sumoutstandtotalest_4493215A']\n",
      "####### NAN count = 840646\n",
      "####### NAN count = 669186\n",
      "####### NAN count = 455612\n",
      "Use these ['pctinstlsallpaidearl3d_427L', 'pctinstlsallpaidlate1d_3546856L']\n",
      "####### NAN count = 458738\n",
      "####### NAN count = 461362\n",
      "####### NAN count = 459827\n",
      "####### NAN count = 460079\n",
      "####### NAN count = 44954\n",
      "####### NAN count = 78526\n",
      "####### NAN count = 131888\n",
      "####### NAN count = 181122\n",
      "####### NAN count = 223240\n",
      "####### NAN count = 445320\n",
      "####### NAN count = 3\n",
      "Use these ['mean_actualdpd_943P']\n",
      "####### NAN count = 305154\n",
      "Use these ['max_annuity_853A', 'mean_annuity_853A']\n",
      "####### NAN count = 308739\n",
      "Use these ['max_credacc_credlmt_575A', 'max_credamount_590A', 'max_downpmt_134A', 'mean_credacc_credlmt_575A', 'mean_credamount_590A', 'mean_downpmt_134A']\n",
      "####### NAN count = 307441\n",
      "Use these ['max_currdebt_94A', 'mean_currdebt_94A']\n",
      "####### NAN count = 419006\n",
      "Use these ['max_mainoccupationinc_437A', 'mean_mainoccupationinc_437A']\n",
      "####### NAN count = 306361\n",
      "Use these ['mean_maxdpdtolerance_577P']\n",
      "####### NAN count = 450969\n",
      "Use these ['max_outstandingdebt_522A', 'mean_outstandingdebt_522A']\n",
      "####### NAN count = 420383\n",
      "####### NAN count = 307551\n",
      "####### NAN count = 477657\n",
      "####### NAN count = 433335\n",
      "Use these ['last_credamount_590A', 'last_downpmt_134A']\n",
      "####### NAN count = 438219\n",
      "####### NAN count = 824731\n",
      "####### NAN count = 312491\n",
      "####### NAN count = 899665\n",
      "####### NAN count = 827764\n",
      "Use these ['max_approvaldate_319D', 'mean_approvaldate_319D']\n",
      "####### NAN count = 442999\n",
      "Use these ['max_dateactivated_425D', 'mean_dateactivated_425D']\n",
      "####### NAN count = 454678\n",
      "Use these ['max_dtlastpmt_581D', 'mean_dtlastpmt_581D']\n",
      "####### NAN count = 703840\n",
      "Use these ['max_dtlastpmtallstes_3545839D', 'mean_dtlastpmtallstes_3545839D']\n",
      "####### NAN count = 548987\n",
      "Use these ['max_employedfrom_700D']\n",
      "####### NAN count = 559169\n",
      "Use these ['max_firstnonzeroinstldate_307D', 'mean_firstnonzeroinstldate_307D']\n",
      "####### NAN count = 334873\n",
      "####### NAN count = 891021\n",
      "####### NAN count = 305203\n",
      "####### NAN count = 920818\n",
      "####### NAN count = 1016761\n",
      "####### NAN count = 1050001\n",
      "####### NAN count = 485683\n",
      "####### NAN count = 961606\n",
      "####### NAN count = 552766\n",
      "Use these ['max_pmtnum_8L']\n",
      "####### NAN count = 321446\n",
      "Use these ['last_pmtnum_8L']\n",
      "####### NAN count = 482174\n",
      "Use these ['max_pmtamount_36A', 'last_pmtamount_36A', 'max_processingdate_168D', 'last_processingdate_168D', 'max_num_group1_5']\n",
      "####### NAN count = 1044394\n",
      "Use these ['mean_credlmt_230A']\n",
      "####### NAN count = 1036944\n",
      "Use these ['mean_credlmt_935A']\n",
      "####### NAN count = 603001\n",
      "Use these ['mean_pmts_dpd_1073P', 'max_dpdmaxdatemonth_89T', 'max_dpdmaxdateyear_596T']\n",
      "####### NAN count = 263166\n",
      "Use these ['max_pmts_dpd_303P', 'mean_dpdmax_757P', 'max_dpdmaxdatemonth_442T', 'max_dpdmaxdateyear_896T', 'mean_pmts_dpd_303P']\n",
      "####### NAN count = 514070\n",
      "Use these ['mean_instlamount_768A']\n",
      "####### NAN count = 606920\n",
      "Use these ['mean_monthlyinstlamount_332A']\n",
      "####### NAN count = 263233\n",
      "Use these ['max_monthlyinstlamount_674A', 'mean_monthlyinstlamount_674A']\n",
      "####### NAN count = 517511\n",
      "Use these ['mean_outstandingamount_354A']\n",
      "####### NAN count = 545885\n",
      "Use these ['mean_outstandingamount_362A']\n",
      "####### NAN count = 636453\n",
      "Use these ['mean_overdueamount_31A']\n",
      "####### NAN count = 512650\n",
      "Use these ['mean_overdueamount_659A', 'max_numberofoverdueinstls_725L']\n",
      "####### NAN count = 263171\n",
      "Use these ['mean_overdueamountmax2_14A', 'mean_totaloutstanddebtvalue_39A', 'mean_dateofcredend_289D', 'mean_dateofcredstart_739D', 'max_lastupdate_1112D', 'mean_lastupdate_1112D', 'max_numberofcontrsvalue_258L', 'max_numberofoverdueinstlmax_1039L', 'max_overdueamountmaxdatemonth_365T', 'max_overdueamountmaxdateyear_2T', 'mean_pmts_overdue_1140A', 'max_pmts_month_158T', 'max_pmts_year_1139T']\n",
      "####### NAN count = 262653\n",
      "Use these ['mean_overdueamountmax2_398A', 'max_dateofcredend_353D', 'max_dateofcredstart_181D', 'mean_dateofcredend_353D', 'max_numberofoverdueinstlmax_1151L']\n",
      "####### NAN count = 512590\n",
      "Use these ['mean_overdueamountmax_35A', 'max_overdueamountmaxdatemonth_284T', 'max_overdueamountmaxdateyear_994T', 'mean_pmts_overdue_1152A']\n",
      "####### NAN count = 513987\n",
      "Use these ['max_residualamount_488A']\n",
      "####### NAN count = 1039597\n",
      "Use these ['mean_residualamount_856A']\n",
      "####### NAN count = 606900\n",
      "Use these ['max_totalamount_6A', 'mean_totalamount_6A']\n",
      "####### NAN count = 545855\n",
      "Use these ['mean_totalamount_996A']\n",
      "####### NAN count = 636448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use these ['mean_totaldebtoverduevalue_718A', 'mean_totaloutstanddebtvalue_668A', 'max_numberofcontrsvalue_358L']\n",
      "####### NAN count = 297072\n",
      "Use these ['max_dateofrealrepmt_138D', 'mean_dateofrealrepmt_138D']\n",
      "####### NAN count = 512961\n",
      "Use these ['max_lastupdate_388D', 'mean_lastupdate_388D']\n",
      "####### NAN count = 512591\n",
      "Use these ['max_numberofoverdueinstlmaxdat_148D']\n",
      "####### NAN count = 802351\n",
      "Use these ['mean_numberofoverdueinstlmaxdat_641D']\n",
      "####### NAN count = 1012361\n",
      "Use these ['mean_overdueamountmax2date_1002D']\n",
      "####### NAN count = 806653\n",
      "Use these ['max_overdueamountmax2date_1142D']\n",
      "####### NAN count = 1007594\n",
      "####### NAN count = 553734\n",
      "####### NAN count = 822517\n",
      "####### NAN count = 745109\n",
      "####### NAN count = 545898\n",
      "####### NAN count = 636545\n",
      "####### NAN count = 545895\n",
      "####### NAN count = 636544\n",
      "####### NAN count = 512657\n",
      "####### NAN count = 561307\n",
      "####### NAN count = 649082\n",
      "Use these ['last_num_group1_6']\n",
      "####### NAN count = 140386\n",
      "Use these ['last_mainoccupationinc_384A', 'last_birth_259D']\n",
      "####### NAN count = 750301\n",
      "Use these ['max_empl_employedfrom_271D']\n",
      "####### NAN count = 959958\n",
      "Use these ['last_personindex_1023L']\n",
      "####### NAN count = 587206\n",
      "####### NAN count = 772\n",
      "####### NAN count = 262659\n",
      "####### NAN count = 512884\n",
      "Use these ['max_pmts_month_706T', 'max_pmts_year_507T']\n",
      "####### NAN count = 512598\n",
      "Use these ['last_pmts_month_158T', 'last_pmts_year_1139T']\n",
      "####### NAN count = 994041\n",
      "Use these ['last_pmts_month_706T', 'last_pmts_year_507T']\n",
      "####### NAN count = 634357\n",
      "Use these ['max_num_group1_13', 'max_num_group2_13', 'last_num_group2_13']\n",
      "####### NAN count = 141371\n",
      "Use these ['max_num_group1_15', 'max_num_group2_15']\n",
      "####### NAN count = 91554\n",
      "['case_id', 'WEEK_NUM', 'target', 'month_decision', 'weekday_decision', 'credamount_770A', 'applicationcnt_361L', 'applications30d_658L', 'applicationscnt_1086L', 'applicationscnt_464L', 'applicationscnt_867L', 'clientscnt_1022L', 'clientscnt_100L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_304L', 'clientscnt_360L', 'clientscnt_493L', 'clientscnt_533L', 'clientscnt_887L', 'clientscnt_946L', 'deferredmnthsnum_166L', 'disbursedcredamount_1113A', 'downpmt_116A', 'homephncnt_628L', 'isbidproduct_1095L', 'mobilephncnt_593L', 'numactivecreds_622L', 'numactivecredschannel_414L', 'numactiverelcontr_750L', 'numcontrs3months_479L', 'numnotactivated_1143L', 'numpmtchanneldd_318L', 'numrejects9m_859L', 'sellerplacecnt_915L', 'max_mainoccupationinc_384A', 'max_birth_259D', 'max_num_group1_9', 'birthdate_574D', 'dateofbirth_337D', 'days180_256L', 'days30_165L', 'days360_512L', 'firstquarter_103L', 'fourthquarter_440L', 'secondquarter_766L', 'thirdquarter_1082L', 'max_debtoutstand_525A', 'max_debtoverdue_47A', 'max_refreshdate_3813885D', 'mean_refreshdate_3813885D', 'pmtscount_423L', 'pmtssum_45A', 'responsedate_1012D', 'responsedate_4527233D', 'actualdpdtolerance_344P', 'amtinstpaidbefduel24m_4187115A', 'numinstlswithdpd5_4187116L', 'annuitynextmonth_57A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'numinstls_657L', 'totalsettled_863A', 'mindbddpdlast24m_3658935P', 'avgdbddpdlast3m_4187120P', 'mindbdtollast24m_4525191P', 'avgdpdtolclosure24_3658938P', 'avginstallast24m_3658937A', 'maxinstallast24m_3658928A', 'avgmaxdpdlast9m_3716943P', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'cntincpaycont9m_3716944L', 'cntpmts24_3658933L', 'commnoinclast6m_3546845L', 'maxdpdfrom6mto36m_3546853P', 'datefirstoffer_1144D', 'datelastunpaid_3546854D', 'daysoverduetolerancedd_3976961L', 'numinsttopaygr_769L', 'dtlastpmtallstes_4499206D', 'eir_270L', 'firstclxcampaign_1125D', 'firstdatedue_489D', 'lastactivateddate_801D', 'lastapplicationdate_877D', 'mean_creationdate_885D', 'max_num_group1', 'last_num_group1', 'max_num_group2_14', 'last_num_group2_14', 'lastapprcredamount_781A', 'lastapprdate_640D', 'lastdelinqdate_224D', 'lastrejectcredamount_222A', 'lastrejectdate_50D', 'maininc_215A', 'mastercontrelectronic_519L', 'mastercontrexist_109L', 'maxannuity_159A', 'maxdebt4_972A', 'maxdpdlast24m_143P', 'maxdpdlast3m_392P', 'maxdpdtolerance_374P', 'maxdbddpdlast1m_3658939P', 'maxdbddpdtollast12m_3658940P', 'maxdbddpdtollast6m_4187119P', 'maxdpdinstldate_3546855D', 'maxdpdinstlnum_3546846P', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'numinstpaidearly_338L', 'numinstpaidearly5d_1087L', 'numinstpaidlate1d_3546852L', 'numincomingpmts_3546848L', 'numinstlsallpaid_934L', 'numinstlswithdpd10_728L', 'numinstlswithoutdpd_562L', 'numinstpaid_4499208L', 'numinstpaidearly3d_3546850L', 'numinstregularpaidest_4493210L', 'numinstpaidearly5dest_4493211L', 'sumoutstandtotalest_4493215A', 'numinstpaidlastcontr_4325080L', 'numinstregularpaid_973L', 'pctinstlsallpaidearl3d_427L', 'pctinstlsallpaidlate1d_3546856L', 'pctinstlsallpaidlat10d_839L', 'pctinstlsallpaidlate4d_3546849L', 'pctinstlsallpaidlate6d_3546844L', 'pmtnum_254L', 'posfpd10lastmonth_333P', 'posfpd30lastmonth_3976960P', 'posfstqpd30lastmonth_3976962P', 'price_1097A', 'sumoutstandtotal_3546847A', 'totaldebt_9A', 'mean_actualdpd_943P', 'max_annuity_853A', 'mean_annuity_853A', 'max_credacc_credlmt_575A', 'max_credamount_590A', 'max_downpmt_134A', 'mean_credacc_credlmt_575A', 'mean_credamount_590A', 'mean_downpmt_134A', 'max_currdebt_94A', 'mean_currdebt_94A', 'max_mainoccupationinc_437A', 'mean_mainoccupationinc_437A', 'mean_maxdpdtolerance_577P', 'max_outstandingdebt_522A', 'mean_outstandingdebt_522A', 'last_actualdpd_943P', 'last_annuity_853A', 'last_credacc_credlmt_575A', 'last_credamount_590A', 'last_downpmt_134A', 'last_currdebt_94A', 'last_mainoccupationinc_437A', 'last_maxdpdtolerance_577P', 'last_outstandingdebt_522A', 'max_approvaldate_319D', 'mean_approvaldate_319D', 'max_dateactivated_425D', 'mean_dateactivated_425D', 'max_dtlastpmt_581D', 'mean_dtlastpmt_581D', 'max_dtlastpmtallstes_3545839D', 'mean_dtlastpmtallstes_3545839D', 'max_employedfrom_700D', 'max_firstnonzeroinstldate_307D', 'mean_firstnonzeroinstldate_307D', 'last_approvaldate_319D', 'last_creationdate_885D', 'last_dateactivated_425D', 'last_dtlastpmtallstes_3545839D', 'last_employedfrom_700D', 'last_firstnonzeroinstldate_307D', 'max_byoccupationinc_3656910L', 'max_childnum_21L', 'max_pmtnum_8L', 'last_pmtnum_8L', 'max_pmtamount_36A', 'last_pmtamount_36A', 'max_processingdate_168D', 'last_processingdate_168D', 'max_num_group1_5', 'mean_credlmt_230A', 'mean_credlmt_935A', 'mean_pmts_dpd_1073P', 'max_dpdmaxdatemonth_89T', 'max_dpdmaxdateyear_596T', 'max_pmts_dpd_303P', 'mean_dpdmax_757P', 'max_dpdmaxdatemonth_442T', 'max_dpdmaxdateyear_896T', 'mean_pmts_dpd_303P', 'mean_instlamount_768A', 'mean_monthlyinstlamount_332A', 'max_monthlyinstlamount_674A', 'mean_monthlyinstlamount_674A', 'mean_outstandingamount_354A', 'mean_outstandingamount_362A', 'mean_overdueamount_31A', 'mean_overdueamount_659A', 'max_numberofoverdueinstls_725L', 'mean_overdueamountmax2_14A', 'mean_totaloutstanddebtvalue_39A', 'mean_dateofcredend_289D', 'mean_dateofcredstart_739D', 'max_lastupdate_1112D', 'mean_lastupdate_1112D', 'max_numberofcontrsvalue_258L', 'max_numberofoverdueinstlmax_1039L', 'max_overdueamountmaxdatemonth_365T', 'max_overdueamountmaxdateyear_2T', 'mean_pmts_overdue_1140A', 'max_pmts_month_158T', 'max_pmts_year_1139T', 'mean_overdueamountmax2_398A', 'max_dateofcredend_353D', 'max_dateofcredstart_181D', 'mean_dateofcredend_353D', 'max_numberofoverdueinstlmax_1151L', 'mean_overdueamountmax_35A', 'max_overdueamountmaxdatemonth_284T', 'max_overdueamountmaxdateyear_994T', 'mean_pmts_overdue_1152A', 'max_residualamount_488A', 'mean_residualamount_856A', 'max_totalamount_6A', 'mean_totalamount_6A', 'mean_totalamount_996A', 'mean_totaldebtoverduevalue_718A', 'mean_totaloutstanddebtvalue_668A', 'max_numberofcontrsvalue_358L', 'max_dateofrealrepmt_138D', 'mean_dateofrealrepmt_138D', 'max_lastupdate_388D', 'mean_lastupdate_388D', 'max_numberofoverdueinstlmaxdat_148D', 'mean_numberofoverdueinstlmaxdat_641D', 'mean_overdueamountmax2date_1002D', 'max_overdueamountmax2date_1142D', 'last_refreshdate_3813885D', 'max_nominalrate_281L', 'max_nominalrate_498L', 'max_numberofinstls_229L', 'max_numberofinstls_320L', 'max_numberofoutstandinstls_520L', 'max_numberofoutstandinstls_59L', 'max_numberofoverdueinstls_834L', 'max_periodicityofpmts_1102L', 'max_periodicityofpmts_837L', 'last_num_group1_6', 'last_mainoccupationinc_384A', 'last_birth_259D', 'max_empl_employedfrom_271D', 'last_personindex_1023L', 'last_persontype_1072L', 'max_collater_valueofguarantee_1124L', 'max_collater_valueofguarantee_876L', 'max_pmts_month_706T', 'max_pmts_year_507T', 'last_pmts_month_158T', 'last_pmts_year_1139T', 'last_pmts_month_706T', 'last_pmts_year_507T', 'max_num_group1_13', 'max_num_group2_13', 'last_num_group2_13', 'max_num_group1_15', 'max_num_group2_15']\n",
      "276\n",
      "389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 1s, sys: 3min 4s, total: 5min 5s\n",
      "Wall time: 5min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = feature_eng(**data_store)\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "del data_store\n",
    "gc.collect()\n",
    "df_train = df_train.pipe(Pipeline.filter_cols)\n",
    "df_train, cat_cols = to_pandas(df_train)\n",
    "df_train = reduce_mem_usage(df_train)\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "nums=df_train.select_dtypes(exclude='category').columns\n",
    "from itertools import combinations, permutations\n",
    "#df_train=df_train[nums]\n",
    "nans_df = df_train[nums].isna()\n",
    "nans_groups={}\n",
    "for col in nums:\n",
    "    cur_group = nans_df[col].sum()\n",
    "    try:\n",
    "        nans_groups[cur_group].append(col)\n",
    "    except:\n",
    "        nans_groups[cur_group]=[col]\n",
    "del nans_df; x=gc.collect()\n",
    "\n",
    "def reduce_group(grps):\n",
    "    use = []\n",
    "    for g in grps:\n",
    "        mx = 0; vx = g[0]\n",
    "        for gg in g:\n",
    "            n = df_train[gg].nunique()\n",
    "            if n>mx:\n",
    "                mx = n\n",
    "                vx = gg\n",
    "            #print(str(gg)+'-'+str(n),', ',end='')\n",
    "        use.append(vx)\n",
    "        #print()\n",
    "    print('Use these',use)\n",
    "    return use\n",
    "\n",
    "def group_columns_by_correlation(matrix, threshold=0.8):\n",
    "    # 计算列之间的相关性\n",
    "    correlation_matrix = matrix.corr()\n",
    "\n",
    "    # 分组列\n",
    "    groups = []\n",
    "    remaining_cols = list(matrix.columns)\n",
    "    while remaining_cols:\n",
    "        col = remaining_cols.pop(0)\n",
    "        group = [col]\n",
    "        correlated_cols = [col]\n",
    "        for c in remaining_cols:\n",
    "            if correlation_matrix.loc[col, c] >= threshold:\n",
    "                group.append(c)\n",
    "                correlated_cols.append(c)\n",
    "        groups.append(group)\n",
    "        remaining_cols = [c for c in remaining_cols if c not in correlated_cols]\n",
    "    \n",
    "    return groups\n",
    "\n",
    "uses=[]\n",
    "for k,v in nans_groups.items():\n",
    "    if len(v)>1:\n",
    "            Vs = nans_groups[k]\n",
    "            #cross_features=list(combinations(Vs, 2))\n",
    "            #make_corr(Vs)\n",
    "            grps= group_columns_by_correlation(df_train[Vs], threshold=0.8)\n",
    "            use=reduce_group(grps)\n",
    "            uses=uses+use\n",
    "            #make_corr(use)\n",
    "    else:\n",
    "        uses=uses+v\n",
    "    print('####### NAN count =',k)\n",
    "print(uses)\n",
    "print(len(uses))\n",
    "uses=uses+list(df_train.select_dtypes(include='category').columns)\n",
    "print(len(uses))\n",
    "df_train=df_train[uses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b193edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()\n",
    "\n",
    "df_train.head(10000).to_excel('Kaggle源码_FinalTrainData.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e553c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"./sample_submission.csv\")\n",
    "device='gpu'\n",
    "#n_samples=200000\n",
    "DRY_RUN = True if sample.shape[0] == 10 else False   \n",
    "if DRY_RUN:\n",
    "    device='cpu'\n",
    "    df_train = df_train.iloc[:50000]\n",
    "    #n_samples=10000\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2460b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d787ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store = {\n",
    "    \"df_base\": read_file(TEST_DIR / \"test_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(TEST_DIR / \"test_static_cb_0.parquet\"),\n",
    "        read_files(TEST_DIR / \"test_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n",
    "        read_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_other_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_person_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_deposit_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n",
    "        read_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n",
    "        read_file(TEST_DIR / \"test_applprev_2.parquet\", 2),\n",
    "        read_file(TEST_DIR / \"test_person_2.parquet\", 2)\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca539f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = feature_eng(**data_store)\n",
    "print(\"test data shape:\\t\", df_test.shape)\n",
    "del data_store\n",
    "gc.collect()\n",
    "df_test = df_test.select([col for col in df_train.columns if col != \"target\"])\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "print(\"test data shape:\\t\", df_test.shape)\n",
    "\n",
    "df_test, cat_cols = to_pandas(df_test, cat_cols)\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aef848",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"target\"]\n",
    "weeks = df_train[\"WEEK_NUM\"]\n",
    "df_train= df_train.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"])\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d94e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 下面可开始机器学习算法"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
